{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523e5780-5ad7-4210-8d13-1000559215b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/data2/patho-vit_5_23'\n",
    "label_csv = None\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "pathid_orig = [f[:-6] for f in os.listdir(os.path.join(path, \"store_4\")) if not f.startswith(\".\")]\n",
    "    # 【:-6】的原因：pyvips切割wsi后，生成的文件自动加上了后缀_files,正好是6个字节\n",
    "    #pathid_orig = [f[:-6] for f in os.listdir(os.path.join(path, \"pseudo_store_3\")) if not f.startswith(\".\")]\n",
    "    \n",
    "if exists(label_csv):\n",
    "    df_label = pd.read_csv(label_csv, index_col = \"pathid\")\n",
    "pathid = []\n",
    "images = []\n",
    "labels = []\n",
    "for i, id in enumerate(pathid_orig):\n",
    "    if len(glob.glob(os.path.join(path, \"store_4\", str(id) + \"_files\",\"0\", \"*.jpeg\"))) != 0:\n",
    "        pathid.append(id)\n",
    "        # 若生成的csv中的images为空缺，需检查图片的格式是否正确。例如，需要区分.jpeg和.jpg\n",
    "        #重要提示：注意最后的文件后缀。images.append(glob.glob(os.path.join(path, \"store_3\", str(id) + \"_files\",\"0\", \"*.jpeg\")))\n",
    "        images.append(glob.glob(os.path.join(path, \"store_4\", str(id) + \"_files\",\"0\", \"*.jpeg\")))\n",
    "        if exists(label_csv):\n",
    "            labels.append(df_label.loc[id][\"labels\"])\n",
    "        else:\n",
    "            labels.append(1e-6)\n",
    "    else:\n",
    "        pathid_orig_2 = [f for f in os.listdir(os.path.join(path, \"store_4\", str(id) + \"_files\")) if not f.startswith(\".\")]\n",
    "        for j, id_2 in enumerate(pathid_orig_2):\n",
    "            pathid.append(id_2)\n",
    "            images.append(glob.glob(os.path.join(path, \"store_4\", str(id) + \"_files\", str(id_2), \"0\", \"*.jpeg\")))\n",
    "            if exists(label_csv):\n",
    "                labels.append(df_label.loc[id][\"labels\"])\n",
    "            else:\n",
    "                labels.append(1e-6)\n",
    "c = {\"pathid\": pathid, \"images\": images, \"labels\": labels}\n",
    "#df_temp = pd.DataFrame(c)\n",
    "#df_temp.to_csv(\"files_label/store_4_temp.csv\", index=False, encoding=\"utf_8_sig\")\n",
    "#torch.save(df.to_dict(orient='list'), \"files_label/store_4_temp.db\")\n",
    "#df = pd.read_csv(\"files_label/store_4_temp.csv\", index_col = \"pathid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb65b7dd-7506-4bc6-acb0-68acfe7f0dcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_csv = \"/data2/patho-vit_5_23_ccsurv/qlyy_surv_label.xlsx\"\n",
    "if exists(label_csv):\n",
    "    df_label = pd.read_excel(label_csv)\n",
    "\n",
    "index_train, index_valid = train_test_split(range(df_label['num'].count()), test_size = 0.3)\n",
    "df_train = df_label[df_label['patientid'].isin(index_train)].reset_index(drop = True)\n",
    "df_valid = df_label[df_label['patientid'].isin(index_valid)].reset_index(drop = True)\n",
    "\n",
    "patientid = []\n",
    "num = []\n",
    "pathid = []\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i, id in enumerate(df_train.patientid):\n",
    "    patientid.append(id)\n",
    "\n",
    "for i, id in enumerate(df_train.num):\n",
    "    num.append(id)\n",
    "    \n",
    "for i, id in enumerate(df_train.pathid):\n",
    "    pathid.append(id)\n",
    "    #images.append(df.loc[id][\"images\"])\n",
    "    index = c[\"pathid\"].index(id)\n",
    "    images.append(c[\"images\"][index])\n",
    "    labels.append(df_train.loc[i].labels)\n",
    "c2 = {\"patientid\": patientid, \"num\": num, \"pathid\": pathid, \"images\": images, \"labels\": labels}\n",
    "df_train = pd.DataFrame(c2) \n",
    "\n",
    "patientid = []\n",
    "num = []\n",
    "pathid = []\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i, id in enumerate(df_valid.patientid):\n",
    "    patientid.append(id)\n",
    "\n",
    "for i, id in enumerate(df_valid.num):\n",
    "    num.append(id)\n",
    "    \n",
    "for i, id in enumerate(df_valid.pathid):\n",
    "    pathid.append(id)\n",
    "    #images.append(df.loc[id][\"images\"])\n",
    "    index = c[\"pathid\"].index(id)\n",
    "    images.append(c[\"images\"][index])\n",
    "    labels.append(df_valid.loc[i].labels)\n",
    "c3 = {\"patientid\": patientid, \"num\": num, \"pathid\": pathid, \"images\": images, \"labels\": labels}\n",
    "df_valid = pd.DataFrame(c3) \n",
    "\n",
    "df_train.to_csv(\"/data2/patho-vit_5_23_ccsurv/files_label/store_4_train_ccsurv.csv\", index=False, encoding=\"utf_8_sig\")\n",
    "torch.save(df_train.to_dict(orient='list'), \"/data2/patho-vit_5_23_ccsurv/files_label/store_4_train_ccsurv.db\")\n",
    "\n",
    "df_valid.to_csv(\"/data2/patho-vit_5_23_ccsurv/files_label/store_4_valid_ccsurv.csv\", index=False, encoding=\"utf_8_sig\")\n",
    "torch.save(df_valid.to_dict(orient='list'), \"/data2/patho-vit_5_23_ccsurv/files_label/store_4_valid_ccsurv.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c7f22-5b1d-4949-b190-f53ba2b293cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4538c45a-c7c3-47c6-9aa8-62c691ec6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = \"/data2/patho-vit_5_23_ccsurv\"\n",
    "# 此处patho_vit后的_5_23为包的版本号\n",
    "# 若此jupyternotebook运行中kernel挂掉，重启后仅需运行此一代码块，然后跳到需要运行的代码块即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354fb17-68be-4f8b-b8f1-11f11462b90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2182c81-3958-4cb9-b43c-2a4333158746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 机场2，为每个补丁抽出特征，为整张切片制作特征图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5164cf96-ccbb-43c1-908d-3e8c943e57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patho_vit.vit_luci2 import ViT as ViT\n",
    "from patho_vit.airport2 import train_features_extractor_gpvit2 as Extractor\n",
    "from patho_vit.airport2 import valid_features_extractor_gpvit2 as Extractor2\n",
    "from collections import OrderedDict\n",
    "path = \"/data2/patho-vit_5_23_ccsurv/up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5e9cd6-8b18-44e0-8d1b-86b531c424da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a7d6b1-67aa-4b30-b733-a996e1014294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extractor3(path, train_lib, transform, batch_size, model, device):\n",
    "    #model = model.to(device)\n",
    "    #model = nn.DataParallel(model)\n",
    "    model.eval()\n",
    "\n",
    "    for i, image in enumerate(train_lib[\"images\"]):\n",
    "        cols = []\n",
    "        rows=[]\n",
    "\n",
    "        for patch in train_lib[\"images\"][i]:\n",
    "            col, row = patch.split(\"/\")[-1].split(\".\")[0].split(\"_\")\n",
    "            cols.append(int(col))\n",
    "            rows.append(int(row))\n",
    "        col_last = sorted(np.array(cols))[-1]\n",
    "        row_last = sorted(np.array(rows))[-1]\n",
    "        image = torch.zeros((row_last+1), (col_last+1), 768)\n",
    "    \n",
    "        patches_batch = []  # 摆渡车\n",
    "        patches_pos = []  # 补丁位置\n",
    "        img_features =[]\n",
    "        for patch in train_lib[\"images\"][i]:\n",
    "            col, row = patch.split(\"/\")[-1].split(\".\")[0].split(\"_\")\n",
    "            patches_pos.append([int(col), int(row)])\n",
    "    \n",
    "        for j, patch in enumerate(train_lib[\"images\"][i]):\n",
    "            torch.cuda.empty_cache() \n",
    "            #patch = cv2.imread(patch)\n",
    "            #patch = cv2.resize(patch, (384, 384))\n",
    "            #patch = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "            patch = Image.open(patch)\n",
    "\n",
    "            patch = transform(patch).unsqueeze(0) \n",
    "            patches_batch.append(patch)\n",
    "        \n",
    "            if ((j+1) % batch_size == 0) or ((j+1) == len(train_lib[\"images\"][i])):\n",
    "                torch.cuda.empty_cache()  \n",
    "                patches_batch = torch.cat(patches_batch, 0).to(device)\n",
    "                _, features = model(patches_batch)\n",
    "                #features = features.softmax(dim = -1)\n",
    "                features = features.cpu().tolist()\n",
    "                for k in range(len(features)):\n",
    "                    img_features.append(features[k])\n",
    "                patches_batch = []  # 清空摆渡车\n",
    "    \n",
    "        for index in range(len(patches_pos)):\n",
    "            batch_range = torch.arange(patches_pos[index][1], patches_pos[index][1] + 1)[:, None]\n",
    "            indices = torch.arange(patches_pos[index][0], patches_pos[index][0] + 1)\n",
    "            image[batch_range, indices] = torch.Tensor(img_features[index]).reshape(1, 1, 768)\n",
    "    \n",
    "        #train_lib[\"images\"][i] = image\n",
    "\n",
    "        torch.save(image, \"store_5_96/{}.db\".format(train_lib[\"pathid\"][i]))\n",
    "\n",
    "    images = []\n",
    "    for i, pathid in enumerate(train_lib[\"pathid\"]):\n",
    "        images.append(os.path.join(path, \"store_5_96\", pathid+\".db\"))\n",
    "    c = {\"pathid\": train_lib[\"pathid\"], \"images\": images, \"labels\": train_lib[\"labels\"]}\n",
    "    df = pd.DataFrame(c)\n",
    "    df.to_csv(\"files_label/store_5_96_exva.csv\", index=False, encoding=\"utf_8_sig\")\n",
    "    torch.save(c, \"files_label/store_5_96_exva.db\")\n",
    "    return \"store_5_96_exva.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dc3a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViT(\n",
    "    image_size = 384,\n",
    "    patch_size = 16,\n",
    "    dim = 768,\n",
    "    depth = 12,\n",
    "    heads = 12,\n",
    "    mlp_dim = 768 * 4,\n",
    "    num_classes = 2\n",
    ")\n",
    "#output, feature = vit(torch.randn(2, 3, 384, 384))\n",
    "#feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f70c2f-72a2-4155-8fc6-b3abaa0070a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入定制vit，加载目标编码器的权重\n",
    "\n",
    "#weights = torch.load(\"output_jepa/gpvit_weight_4_22_epoch_1.pt\")\n",
    "weights = torch.load(\"/data2/patho-vit_5_23_ccsurv/up/13/12.4/gpvit_weight_12_4_epoch_18.pt\", map_location=torch.device('cpu'))\n",
    "path = \"/data2/patho-vit_5_23_ccsurv/up\"\n",
    "new_dict = OrderedDict()\n",
    "for k, v in weights.items():\n",
    "    if \"module.target_encoder\" in k:\n",
    "        new_key = k[22:]\n",
    "        new_dict[new_key] = v\n",
    "\n",
    "vit = ViT(\n",
    "    image_size = 384,\n",
    "    patch_size = 16,\n",
    "    dim = 768,\n",
    "    depth = 12,\n",
    "    heads = 12,\n",
    "    mlp_dim = 768 * 4,\n",
    "    num_classes = 1000\n",
    ")\n",
    "vit.to(device)\n",
    "vit.load_state_dict(new_dict, strict = False)\n",
    "vit = nn.DataParallel(vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24dde870",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m valid_lib \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data2/patho-vit_5_23_oc/pla/patient/files_label/store_4_valid_pla.db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m exva_lib \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data2/patho-vit_5_23_oc/pla/patient/files_label/store_4_qlyy.db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m extractor \u001b[38;5;241m=\u001b[39m \u001b[43mExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lib\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_lib\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m extractor2 \u001b[38;5;241m=\u001b[39m Extractor2(path \u001b[38;5;241m=\u001b[39m path, train_lib \u001b[38;5;241m=\u001b[39m valid_lib, transform \u001b[38;5;241m=\u001b[39m transform, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, model \u001b[38;5;241m=\u001b[39m vit, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[1;32m     15\u001b[0m extractor3 \u001b[38;5;241m=\u001b[39m Extractor3(path \u001b[38;5;241m=\u001b[39m path, train_lib \u001b[38;5;241m=\u001b[39m exva_lib, transform \u001b[38;5;241m=\u001b[39m transform, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, model \u001b[38;5;241m=\u001b[39m vit, device \u001b[38;5;241m=\u001b[39m device)\n",
      "File \u001b[0;32m/data2/patho-vit_5_23_ccsurv/patient/up/patho_vit/airport2.py:325\u001b[0m, in \u001b[0;36mtrain_features_extractor_gpvit2\u001b[0;34m(path, train_lib, transform, batch_size, model, device)\u001b[0m\n\u001b[1;32m    323\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()  \n\u001b[1;32m    324\u001b[0m patches_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(patches_batch, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 325\u001b[0m _, features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m#features = features.softmax(dim = -1)\u001b[39;00m\n\u001b[1;32m    327\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:78\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 78\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/2023/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 一个文件夹一个文件夹的抽特征，并重构（384，384，768）的图像\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize([384, 384]),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                             std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "#train_lib = \"files/store_5_train_{}.db\".format((n+1) * 25)\n",
    "train_lib = torch.load(\"/data2/patho-vit_5_23_ccsurv/files_label/store_4_train_ccsurv.db\")\n",
    "valid_lib = torch.load(\"/data2/patho-vit_5_23_ccsurv/files_label/store_4_valid_ccsurv.db\")\n",
    "exva_lib = torch.load(\"/data2/patho-vit_5_23_ccsurv/SZL_exva/files/store_4.db\")\n",
    "\n",
    "extractor = Extractor(path = path, train_lib = train_lib, transform = transform, batch_size = 200, model = vit, device = device)\n",
    "extractor2 = Extractor2(path = path, train_lib = valid_lib, transform = transform, batch_size = 200, model = vit, device = device)\n",
    "extractor3 = Extractor3(path = path, train_lib = exva_lib, transform = transform, batch_size = 200, model = vit, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4641f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdd09e-6201-475b-a036-b2793a111e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cbc241-a844-4f1a-a6c4-b9623b852b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3442bfd-35cc-4b63-8398-275e24f65cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c425b6f-54c6-4551-a0b0-59addd621620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023",
   "language": "python",
   "name": "2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
