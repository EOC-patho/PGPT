{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4538c45a-c7c3-47c6-9aa8-62c691ec6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import copy\n",
    "from functools import wraps, partial\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from einops import repeat, rearrange \n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ef25c5-1fb8-473f-987f-41b1f299bf34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = \"/data2/patho-vit_5_23_ccsurv/patient/low\"\n",
    "# 此处patho_vit后的_5_23为包的版本号\n",
    "# 若此jupyternotebook运行中kernel挂掉，重启后仅需运行此一代码块，然后跳到需要运行的代码块即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f847f0eb-2603-4d81-b8dc-824251721a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27cb24f-f985-454a-ab67-f1edc8bd820d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b38b00e9-2181-4d26-899c-5e420c1cb4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from patho_vit.vit_luci import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10355b0a-c3b4-4770-a749-c66bd3ca89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "# 取决于gpu数量，原始文献为50，若报错CUDA OUT OF MEMORY,则减少batch_size个数。此外，需关闭kernel重启，只重启机场1代码即可。\n",
    "num_workers = 0\n",
    "# 取决于cpu数量，原始文献此处为4，可从0逐渐增加\n",
    "\n",
    "epochs = 10000\n",
    "# 原始文献中默认值为50\n",
    "test_every = 1\n",
    "# 多少次训练后，进行一次验证。原始文献中默认值为10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba76d091-4c4e-4312-b29d-52d20bbc0eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit = ViT(\n",
    "    image_size = 96,\n",
    "    patch_size = 2, \n",
    "    channels = 768,\n",
    "    dim = 768 * 2,\n",
    "    depth = 35,\n",
    "    heads = 12 * 2,\n",
    "    mlp_dim = 768 * 2 * 4,\n",
    "    num_classes = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2726c82e-a2d3-4d74-83c9-66e721b11c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.randn(1, 768, 96, 96)\n",
    "#from thop import profile\n",
    "#flops, params =                  profile(vit, inputs =                               (img, ))  \n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39e5e9e-f2d1-4b7e-8940-eb0db2cc09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for params in vit.parameters():\n",
    "#    params.requires_grad = False\n",
    "\n",
    "#vit.mlp_head = nn.Sequential(\n",
    "#            nn.Linear((48 * 48 + 1) * 768 * 2, 512),\n",
    "#            nn.GELU(),\n",
    "#            nn.Linear(512, 512),\n",
    "#            nn.GELU(),\n",
    "#            nn.Linear(512, 512),\n",
    "#            nn.LayerNorm(512),\n",
    "#            nn.Linear(512, 3)\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2222799-1306-4a1a-b776-8664d81a968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入定制vit，加载目标编码器的权重\n",
    "#weights = torch.load(\"/data2/patho-vit_5_23_oc/up/13/gpvit_weight_6_24_epoch_1.pt\")\n",
    "\n",
    "weights = torch.load(\"/data2/patho-vit_5_23_ccsurv/patient/low/57/gpvit_weight_12_23_epoch_2.pt\")\n",
    "#new_dict = OrderedDict()\n",
    "#for k, v in weights.items():\n",
    "#    if \"module.target_encoder\" not in k:\n",
    "#        new_key = k[7:]\n",
    "#        new_dict[new_key] = v\n",
    "\n",
    "#jepa = Jepa()\n",
    "#jepa.to(device)\n",
    "#jepa.load_state_dict(new_dict, strict = False)\n",
    "#jepa = nn.DataParallel(jepa)\n",
    "new_dict = OrderedDict()\n",
    "for k, v in weights.items():\n",
    "    if \"module.target_encoder\" in k:\n",
    "        new_key = k[22:]\n",
    "        new_dict[new_key] = v\n",
    "\n",
    "vit.to(device)\n",
    "vit.load_state_dict(new_dict, strict = False)\n",
    "vit = nn.DataParallel(vit)\n",
    "##vit.to(device)\n",
    "#vit = nn.DataParallel(vit)\n",
    "#weights = torch.load(\"/data2/patho-vit_5_23_ccim/low/57/checkpoint_2classes_1epoch_8.pth\")\n",
    "#vit.load_state_dict(weights, strict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8464f16-45ec-4238-a09e-b6406a2d182f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac177420-b518-4086-a1ea-3d0e2ef4d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer3dataset(torch.utils.data.Dataset):\n",
    "    # 为第二层重构的图制作数据集，大小为（96，96，768）\n",
    "    def __init__(self, libraryfile = \"\", transform=None, subsample=-1):\n",
    "        file = pd.read_csv(libraryfile)\n",
    "        # 原始表格一个病人一行，一共三列，第一列为病理号，\n",
    "        # 每行的第二列为一个列表，其中是新图片的路径，\n",
    "        # 第三列为标签值\n",
    "        self.pathid = file[\"pathid\"]\n",
    "        self.images = file[\"images\"]\n",
    "        self.labels = file[\"labels\"]\n",
    "        \n",
    "        self.subsample = subsample\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = torch.load(self.images[index])\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.subsample != -1 and self.transform is not None:\n",
    "            \n",
    "            image = self.transform(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            image = F.interpolate(image, size =(self.subsample, self.subsample))\n",
    "            image = image.squeeze(0)\n",
    "            image = image.to(torch.float32)\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        pathid = self.pathid[index]\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pathid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a360dbd8-5659-4ca8-934a-77b2d7a93a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "                             std=(0.229, 0.224, 0.225))\n",
    "#train_lib_0 = \"/data2/patho-vit_5_23_ccim/low/files_label/store_4_lung_train.db\"\n",
    "train_lib_1 = \"/data2/patho-vit_5_23_ccsurv/patient/low/files_label/store_5_96_train.csv\"\n",
    "valid_lib = \"/data2/patho-vit_5_23_ccsurv/patient/low/files_label/store_5_96_valid.csv\"\n",
    "valid_lib_1 = \"/data2/patho-vit_5_23_ccsurv/patient/low/files_label/store_5_96_exva.csv\"\n",
    "\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset_1 = layer3dataset(train_lib_1, transform = transform, subsample = 96)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset_1,\n",
    "    batch_size = batch_size, shuffle = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n",
    "valid_dataset = layer3dataset(valid_lib, transform = transform, subsample = 96)\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = batch_size, shuffle = False,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n",
    "valid_dataset_1 = layer3dataset(valid_lib_1, transform = transform, subsample = 96)\n",
    "valid_loader_1 = torch.utils.data.DataLoader(\n",
    "    valid_dataset_1,\n",
    "    batch_size = batch_size, shuffle = False,\n",
    "    num_workers = num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ce2649-9627-44f2-b5f6-0e190d49b80b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Step [186/359] Loss: 0.0753776804\n",
      "Epoch [1/10000], Loss_cc: 0.6925, Acc_cc: 0.8210\n",
      "Epoch : 1 - val_loss: 0.6543, val_acc: 0.8333 - ba: 0.5000\n",
      "\n",
      "Epoch : 1 - test_acc: 0.9127 - ba_test: 0.5120\n",
      "\n",
      "Epoch [2/10000], Step [186/359] Loss: 0.5931120515\n",
      "Epoch [2/10000], Loss_cc: 0.6789, Acc_cc: 0.8043\n",
      "Epoch : 2 - val_loss: 0.6286, val_acc: 0.8301 - ba: 0.4980\n",
      "\n",
      "Epoch : 2 - test_acc: 0.9245 - ba_test: 0.5000\n",
      "\n",
      "Epoch [3/10000], Step [186/359] Loss: 0.3658606112\n",
      "Epoch [3/10000], Loss_cc: 0.5671, Acc_cc: 0.8691\n",
      "Epoch : 3 - val_loss: 0.6236, val_acc: 0.7059 - ba: 0.5529\n",
      "\n",
      "Epoch : 3 - test_acc: 0.7343 - ba_test: 0.5254\n",
      "\n",
      "Epoch [4/10000], Step [186/359] Loss: 0.0651621968\n",
      "Epoch [4/10000], Loss_cc: 0.5495, Acc_cc: 0.8712\n",
      "Epoch : 4 - val_loss: 0.7507, val_acc: 0.8301 - ba: 0.4980\n",
      "\n",
      "Epoch : 4 - test_acc: 0.9245 - ba_test: 0.5000\n",
      "\n",
      "Epoch [5/10000], Step [186/359] Loss: 0.1076546088\n",
      "Epoch [5/10000], Loss_cc: 0.4995, Acc_cc: 0.8802\n",
      "Epoch : 5 - val_loss: 0.6480, val_acc: 0.7859 - ba: 0.5382\n",
      "\n",
      "Epoch : 5 - test_acc: 0.8539 - ba_test: 0.4986\n",
      "\n",
      "Epoch [6/10000], Step [186/359] Loss: 0.1037507579\n",
      "Epoch [6/10000], Loss_cc: 0.4576, Acc_cc: 0.8740\n",
      "Epoch : 6 - val_loss: 0.6188, val_acc: 0.8056 - ba: 0.5225\n",
      "\n",
      "Epoch : 6 - test_acc: 0.8892 - ba_test: 0.4993\n",
      "\n",
      "Epoch [7/10000], Step [186/359] Loss: 0.0939720869\n",
      "Epoch [7/10000], Loss_cc: 0.4441, Acc_cc: 0.8921\n",
      "Epoch : 7 - val_loss: 0.9002, val_acc: 0.8333 - ba: 0.5039\n",
      "\n",
      "Epoch : 7 - test_acc: 0.9186 - ba_test: 0.4968\n",
      "\n",
      "Epoch [8/10000], Step [186/359] Loss: 1.9031219482\n",
      "Epoch [8/10000], Loss_cc: 0.4169, Acc_cc: 0.9123\n",
      "Epoch : 8 - val_loss: 0.7089, val_acc: 0.8252 - ba: 0.5225\n",
      "\n",
      "Epoch : 8 - test_acc: 0.9098 - ba_test: 0.4920\n",
      "\n",
      "Epoch [9/10000], Step [186/359] Loss: 1.3252978325\n",
      "Epoch [9/10000], Loss_cc: 0.4700, Acc_cc: 0.8872\n",
      "Epoch : 9 - val_loss: 0.7483, val_acc: 0.8186 - ba: 0.5147\n",
      "\n",
      "Epoch : 9 - test_acc: 0.9127 - ba_test: 0.4936\n",
      "\n",
      "Epoch [10/10000], Step [186/359] Loss: 1.9986819029\n",
      "Epoch [10/10000], Loss_cc: 0.3968, Acc_cc: 0.9025\n",
      "Epoch : 10 - val_loss: 0.9429, val_acc: 0.8333 - ba: 0.5000\n",
      "\n",
      "Epoch : 10 - test_acc: 0.9216 - ba_test: 0.4984\n",
      "\n",
      "Epoch [11/10000], Step [186/359] Loss: 0.2138889432\n",
      "Epoch [11/10000], Loss_cc: 0.4017, Acc_cc: 0.9046\n",
      "Epoch : 11 - val_loss: 0.6542, val_acc: 0.7582 - ba: 0.5765\n",
      "\n",
      "Epoch : 11 - test_acc: 0.7961 - ba_test: 0.5772\n",
      "\n",
      "Epoch [12/10000], Step [186/359] Loss: 0.3192139864\n",
      "Epoch [12/10000], Loss_cc: 0.3517, Acc_cc: 0.9143\n",
      "Epoch : 12 - val_loss: 0.9937, val_acc: 0.8154 - ba: 0.5559\n",
      "\n",
      "Epoch : 12 - test_acc: 0.8873 - ba_test: 0.5897\n",
      "\n",
      "Epoch [13/10000], Step [186/359] Loss: 0.0604845621\n",
      "Epoch [13/10000], Loss_cc: 0.3349, Acc_cc: 0.9136\n",
      "Epoch : 13 - val_loss: 0.9505, val_acc: 0.8023 - ba: 0.5559\n",
      "\n",
      "Epoch : 13 - test_acc: 0.8588 - ba_test: 0.5922\n",
      "\n",
      "Epoch [14/10000], Step [186/359] Loss: 1.6882344484\n",
      "Epoch [14/10000], Loss_cc: 0.2962, Acc_cc: 0.9248\n",
      "Epoch : 14 - val_loss: 1.6265, val_acc: 0.8317 - ba: 0.4990\n",
      "\n",
      "Epoch : 14 - test_acc: 0.9245 - ba_test: 0.5000\n",
      "\n",
      "Epoch [15/10000], Step [186/359] Loss: 0.5656744242\n",
      "Epoch [15/10000], Loss_cc: 0.3484, Acc_cc: 0.9046\n",
      "Epoch : 15 - val_loss: 1.1098, val_acc: 0.7958 - ba: 0.5363\n",
      "\n",
      "Epoch : 15 - test_acc: 0.8863 - ba_test: 0.5529\n",
      "\n",
      "Epoch [16/10000], Step [186/359] Loss: 0.4815970063\n",
      "Epoch [16/10000], Loss_cc: 0.3492, Acc_cc: 0.8941\n",
      "Epoch : 16 - val_loss: 0.8597, val_acc: 0.8268 - ba: 0.5235\n",
      "\n",
      "Epoch : 16 - test_acc: 0.9127 - ba_test: 0.5120\n",
      "\n",
      "Epoch [17/10000], Step [186/359] Loss: 1.1660289764\n",
      "Epoch [17/10000], Loss_cc: 0.3270, Acc_cc: 0.9157\n",
      "Epoch : 17 - val_loss: 1.0874, val_acc: 0.8203 - ba: 0.5118\n",
      "\n",
      "Epoch : 17 - test_acc: 0.8980 - ba_test: 0.4857\n",
      "\n",
      "Epoch [18/10000], Step [186/359] Loss: 0.0391430967\n",
      "Epoch [18/10000], Loss_cc: 0.2641, Acc_cc: 0.9318\n",
      "Epoch : 18 - val_loss: 0.8785, val_acc: 0.8203 - ba: 0.5000\n",
      "\n",
      "Epoch : 18 - test_acc: 0.8951 - ba_test: 0.4841\n",
      "\n",
      "Epoch [19/10000], Step [186/359] Loss: 0.1069160476\n",
      "Epoch [19/10000], Loss_cc: 0.2507, Acc_cc: 0.9422\n",
      "Epoch : 19 - val_loss: 1.0349, val_acc: 0.7974 - ba: 0.4980\n",
      "\n",
      "Epoch : 19 - test_acc: 0.7804 - ba_test: 0.4404\n",
      "\n",
      "Epoch [20/10000], Step [186/359] Loss: 0.0962539166\n",
      "Epoch [20/10000], Loss_cc: 0.2302, Acc_cc: 0.9297\n",
      "Epoch : 20 - val_loss: 0.9747, val_acc: 0.7549 - ba: 0.5353\n",
      "\n",
      "Epoch : 20 - test_acc: 0.7843 - ba_test: 0.5892\n",
      "\n",
      "Epoch [21/10000], Step [186/359] Loss: 0.1373670846\n",
      "Epoch [21/10000], Loss_cc: 0.2359, Acc_cc: 0.9359\n",
      "Epoch : 21 - val_loss: 1.1564, val_acc: 0.7892 - ba: 0.5363\n",
      "\n",
      "Epoch : 21 - test_acc: 0.8186 - ba_test: 0.5163\n",
      "\n",
      "Epoch [22/10000], Step [186/359] Loss: 0.0083484007\n",
      "Epoch [22/10000], Loss_cc: 0.1756, Acc_cc: 0.9610\n",
      "Epoch : 22 - val_loss: 1.3082, val_acc: 0.8105 - ba: 0.5020\n",
      "\n",
      "Epoch : 22 - test_acc: 0.8853 - ba_test: 0.5161\n",
      "\n",
      "Epoch [23/10000], Step [186/359] Loss: 0.0414012559\n",
      "Epoch [23/10000], Loss_cc: 0.1413, Acc_cc: 0.9666\n",
      "Epoch : 23 - val_loss: 1.8319, val_acc: 0.8154 - ba: 0.4971\n",
      "\n",
      "Epoch : 23 - test_acc: 0.8745 - ba_test: 0.4913\n",
      "\n",
      "Epoch [24/10000], Step [186/359] Loss: 0.0013656314\n",
      "Epoch [24/10000], Loss_cc: 0.1766, Acc_cc: 0.9540\n",
      "Epoch : 24 - val_loss: 0.7044, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 24 - test_acc: 0.8373 - ba_test: 0.5259\n",
      "\n",
      "Epoch [25/10000], Step [186/359] Loss: 0.0051670130\n",
      "Epoch [25/10000], Loss_cc: 0.1388, Acc_cc: 0.9624\n",
      "Epoch : 25 - val_loss: 0.9258, val_acc: 0.7810 - ba: 0.5275\n",
      "\n",
      "Epoch : 25 - test_acc: 0.7804 - ba_test: 0.5508\n",
      "\n",
      "Epoch [26/10000], Step [186/359] Loss: 0.0083425995\n",
      "Epoch [26/10000], Loss_cc: 0.1335, Acc_cc: 0.9624\n",
      "Epoch : 26 - val_loss: 1.5799, val_acc: 0.7745 - ba: 0.5510\n",
      "\n",
      "Epoch : 26 - test_acc: 0.7784 - ba_test: 0.5676\n",
      "\n",
      "Epoch [27/10000], Step [186/359] Loss: 0.0155627234\n",
      "Epoch [27/10000], Loss_cc: 0.1580, Acc_cc: 0.9652\n",
      "Epoch : 27 - val_loss: 1.7698, val_acc: 0.8056 - ba: 0.5265\n",
      "\n",
      "Epoch : 27 - test_acc: 0.8343 - ba_test: 0.5611\n",
      "\n",
      "Epoch [28/10000], Step [186/359] Loss: 0.0003517966\n",
      "Epoch [28/10000], Loss_cc: 0.1544, Acc_cc: 0.9638\n",
      "Epoch : 28 - val_loss: 0.7975, val_acc: 0.7827 - ba: 0.5363\n",
      "\n",
      "Epoch : 28 - test_acc: 0.7735 - ba_test: 0.5292\n",
      "\n",
      "Epoch [29/10000], Step [186/359] Loss: 0.0056931693\n",
      "Epoch [29/10000], Loss_cc: 0.1818, Acc_cc: 0.9533\n",
      "Epoch : 29 - val_loss: 1.3196, val_acc: 0.7810 - ba: 0.5314\n",
      "\n",
      "Epoch : 29 - test_acc: 0.7402 - ba_test: 0.5101\n",
      "\n",
      "Epoch [30/10000], Step [186/359] Loss: 0.0465547703\n",
      "Epoch [30/10000], Loss_cc: 0.1293, Acc_cc: 0.9638\n",
      "Epoch : 30 - val_loss: 1.4548, val_acc: 0.8252 - ba: 0.5147\n",
      "\n",
      "Epoch : 30 - test_acc: 0.9049 - ba_test: 0.5257\n",
      "\n",
      "Epoch [31/10000], Step [186/359] Loss: 0.0001318024\n",
      "Epoch [31/10000], Loss_cc: 0.1202, Acc_cc: 0.9735\n",
      "Epoch : 31 - val_loss: 2.3508, val_acc: 0.8186 - ba: 0.5186\n",
      "\n",
      "Epoch : 31 - test_acc: 0.8980 - ba_test: 0.4857\n",
      "\n",
      "Epoch [32/10000], Step [186/359] Loss: 0.0069988607\n",
      "Epoch [32/10000], Loss_cc: 0.0810, Acc_cc: 0.9770\n",
      "Epoch : 32 - val_loss: 2.3897, val_acc: 0.8317 - ba: 0.5304\n",
      "\n",
      "Epoch : 32 - test_acc: 0.8902 - ba_test: 0.4993\n",
      "\n",
      "Epoch [33/10000], Step [186/359] Loss: 0.0006158224\n",
      "Epoch [33/10000], Loss_cc: 0.0819, Acc_cc: 0.9770\n",
      "Epoch : 33 - val_loss: 1.4620, val_acc: 0.7974 - ba: 0.5255\n",
      "\n",
      "Epoch : 33 - test_acc: 0.8225 - ba_test: 0.5363\n",
      "\n",
      "Epoch [34/10000], Step [186/359] Loss: 0.0120236846\n",
      "Epoch [34/10000], Loss_cc: 0.0651, Acc_cc: 0.9889\n",
      "Epoch : 34 - val_loss: 2.5824, val_acc: 0.8170 - ba: 0.5137\n",
      "\n",
      "Epoch : 34 - test_acc: 0.8686 - ba_test: 0.4882\n",
      "\n",
      "Epoch [35/10000], Step [186/359] Loss: 0.4873558879\n",
      "Epoch [35/10000], Loss_cc: 0.0431, Acc_cc: 0.9902\n",
      "Epoch : 35 - val_loss: 2.6430, val_acc: 0.8317 - ba: 0.5186\n",
      "\n",
      "Epoch : 35 - test_acc: 0.8784 - ba_test: 0.4929\n",
      "\n",
      "Epoch [36/10000], Step [186/359] Loss: 0.0000082453\n",
      "Epoch [36/10000], Loss_cc: 0.0864, Acc_cc: 0.9791\n",
      "Epoch : 36 - val_loss: 2.1672, val_acc: 0.8350 - ba: 0.5127\n",
      "\n",
      "Epoch : 36 - test_acc: 0.9098 - ba_test: 0.4920\n",
      "\n",
      "Epoch [37/10000], Step [186/359] Loss: 0.0003258515\n",
      "Epoch [37/10000], Loss_cc: 0.0724, Acc_cc: 0.9840\n",
      "Epoch : 37 - val_loss: 2.1690, val_acc: 0.8252 - ba: 0.5029\n",
      "\n",
      "Epoch : 37 - test_acc: 0.9069 - ba_test: 0.4904\n",
      "\n",
      "Epoch [38/10000], Step [186/359] Loss: 0.0055023986\n",
      "Epoch [38/10000], Loss_cc: 0.0956, Acc_cc: 0.9777\n",
      "Epoch : 38 - val_loss: 1.6388, val_acc: 0.7843 - ba: 0.5294\n",
      "\n",
      "Epoch : 38 - test_acc: 0.7451 - ba_test: 0.4949\n",
      "\n",
      "Epoch [39/10000], Step [186/359] Loss: 0.0004186440\n",
      "Epoch [39/10000], Loss_cc: 0.0617, Acc_cc: 0.9882\n",
      "Epoch : 39 - val_loss: 1.6909, val_acc: 0.8039 - ba: 0.5294\n",
      "\n",
      "Epoch : 39 - test_acc: 0.8127 - ba_test: 0.5315\n",
      "\n",
      "Epoch [40/10000], Step [186/359] Loss: 0.0000323643\n",
      "Epoch [40/10000], Loss_cc: 0.0562, Acc_cc: 0.9854\n",
      "Epoch : 40 - val_loss: 2.6215, val_acc: 0.8235 - ba: 0.4980\n",
      "\n",
      "Epoch : 40 - test_acc: 0.9157 - ba_test: 0.5504\n",
      "\n",
      "Epoch [41/10000], Step [186/359] Loss: 0.0205710419\n",
      "Epoch [41/10000], Loss_cc: 0.0377, Acc_cc: 0.9909\n",
      "Epoch : 41 - val_loss: 2.6658, val_acc: 0.7974 - ba: 0.5176\n",
      "\n",
      "Epoch : 41 - test_acc: 0.8304 - ba_test: 0.5227\n",
      "\n",
      "Epoch [42/10000], Step [186/359] Loss: 0.0014714873\n",
      "Epoch [42/10000], Loss_cc: 0.0624, Acc_cc: 0.9868\n",
      "Epoch : 42 - val_loss: 2.5688, val_acc: 0.8301 - ba: 0.5333\n",
      "\n",
      "Epoch : 42 - test_acc: 0.8627 - ba_test: 0.5218\n",
      "\n",
      "Epoch [43/10000], Step [186/359] Loss: 0.0038312087\n",
      "Epoch [43/10000], Loss_cc: 0.0370, Acc_cc: 0.9889\n",
      "Epoch : 43 - val_loss: 2.7492, val_acc: 0.8235 - ba: 0.5098\n",
      "\n",
      "Epoch : 43 - test_acc: 0.8892 - ba_test: 0.5177\n",
      "\n",
      "Epoch [44/10000], Step [186/359] Loss: 0.0001609487\n",
      "Epoch [44/10000], Loss_cc: 0.0488, Acc_cc: 0.9882\n",
      "Epoch : 44 - val_loss: 1.6243, val_acc: 0.8023 - ba: 0.5363\n",
      "\n",
      "Epoch : 44 - test_acc: 0.8275 - ba_test: 0.5211\n",
      "\n",
      "Epoch [45/10000], Step [186/359] Loss: 0.0125948964\n",
      "Epoch [45/10000], Loss_cc: 0.0225, Acc_cc: 0.9937\n",
      "Epoch : 45 - val_loss: 2.3427, val_acc: 0.7745 - ba: 0.5196\n",
      "\n",
      "Epoch : 45 - test_acc: 0.7569 - ba_test: 0.5381\n",
      "\n",
      "Epoch [46/10000], Step [186/359] Loss: 0.0000905002\n",
      "Epoch [46/10000], Loss_cc: 0.0464, Acc_cc: 0.9896\n",
      "Epoch : 46 - val_loss: 2.4205, val_acc: 0.7794 - ba: 0.5147\n",
      "\n",
      "Epoch : 46 - test_acc: 0.8020 - ba_test: 0.5436\n",
      "\n",
      "Epoch [47/10000], Step [186/359] Loss: 0.0139235742\n",
      "Epoch [47/10000], Loss_cc: 0.0285, Acc_cc: 0.9958\n",
      "Epoch : 47 - val_loss: 2.2089, val_acc: 0.7974 - ba: 0.5176\n",
      "\n",
      "Epoch : 47 - test_acc: 0.7833 - ba_test: 0.4972\n",
      "\n",
      "Epoch [48/10000], Step [186/359] Loss: 0.0036523403\n",
      "Epoch [48/10000], Loss_cc: 0.0157, Acc_cc: 0.9965\n",
      "Epoch : 48 - val_loss: 2.2208, val_acc: 0.8121 - ba: 0.5382\n",
      "\n",
      "Epoch : 48 - test_acc: 0.7922 - ba_test: 0.5388\n",
      "\n",
      "Epoch [49/10000], Step [186/359] Loss: 0.0007326614\n",
      "Epoch [49/10000], Loss_cc: 0.0259, Acc_cc: 0.9958\n",
      "Epoch : 49 - val_loss: 2.7815, val_acc: 0.7761 - ba: 0.5520\n",
      "\n",
      "Epoch : 49 - test_acc: 0.7275 - ba_test: 0.5590\n",
      "\n",
      "Epoch [50/10000], Step [186/359] Loss: 0.0003743904\n",
      "Epoch [50/10000], Loss_cc: 0.0193, Acc_cc: 0.9937\n",
      "Epoch : 50 - val_loss: 3.0562, val_acc: 0.8121 - ba: 0.5108\n",
      "\n",
      "Epoch : 50 - test_acc: 0.8569 - ba_test: 0.5186\n",
      "\n",
      "Epoch [51/10000], Step [186/359] Loss: 0.0004399460\n",
      "Epoch [51/10000], Loss_cc: 0.0404, Acc_cc: 0.9896\n",
      "Epoch : 51 - val_loss: 1.8486, val_acc: 0.7500 - ba: 0.5402\n",
      "\n",
      "Epoch : 51 - test_acc: 0.6931 - ba_test: 0.5767\n",
      "\n",
      "Epoch [52/10000], Step [186/359] Loss: 0.0000004768\n",
      "Epoch [52/10000], Loss_cc: 0.0129, Acc_cc: 0.9979\n",
      "Epoch : 52 - val_loss: 3.0098, val_acc: 0.7876 - ba: 0.5118\n",
      "\n",
      "Epoch : 52 - test_acc: 0.8010 - ba_test: 0.5620\n",
      "\n",
      "Epoch [53/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [53/10000], Loss_cc: 0.0054, Acc_cc: 0.9972\n",
      "Epoch : 53 - val_loss: 3.8659, val_acc: 0.8121 - ba: 0.5186\n",
      "\n",
      "Epoch : 53 - test_acc: 0.8745 - ba_test: 0.5466\n",
      "\n",
      "Epoch [54/10000], Step [186/359] Loss: 0.0000004768\n",
      "Epoch [54/10000], Loss_cc: 0.0322, Acc_cc: 0.9937\n",
      "Epoch : 54 - val_loss: 3.7983, val_acc: 0.8072 - ba: 0.5078\n",
      "\n",
      "Epoch : 54 - test_acc: 0.8863 - ba_test: 0.5161\n",
      "\n",
      "Epoch [55/10000], Step [186/359] Loss: 0.0000108478\n",
      "Epoch [55/10000], Loss_cc: 0.0060, Acc_cc: 0.9993\n",
      "Epoch : 55 - val_loss: 4.4598, val_acc: 0.7958 - ba: 0.5206\n",
      "\n",
      "Epoch : 55 - test_acc: 0.8127 - ba_test: 0.4763\n",
      "\n",
      "Epoch [56/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [56/10000], Loss_cc: 0.0147, Acc_cc: 0.9944\n",
      "Epoch : 56 - val_loss: 4.3316, val_acc: 0.7941 - ba: 0.5275\n",
      "\n",
      "Epoch : 56 - test_acc: 0.8304 - ba_test: 0.5043\n",
      "\n",
      "Epoch [57/10000], Step [186/359] Loss: 0.0000087320\n",
      "Epoch [57/10000], Loss_cc: 0.0414, Acc_cc: 0.9937\n",
      "Epoch : 57 - val_loss: 3.5219, val_acc: 0.8203 - ba: 0.5118\n",
      "\n",
      "Epoch : 57 - test_acc: 0.8892 - ba_test: 0.5177\n",
      "\n",
      "Epoch [58/10000], Step [186/359] Loss: 0.0000009835\n",
      "Epoch [58/10000], Loss_cc: 0.0105, Acc_cc: 0.9965\n",
      "Epoch : 58 - val_loss: 3.4786, val_acc: 0.7631 - ba: 0.5127\n",
      "\n",
      "Epoch : 58 - test_acc: 0.7775 - ba_test: 0.5861\n",
      "\n",
      "Epoch [59/10000], Step [186/359] Loss: 0.0000003874\n",
      "Epoch [59/10000], Loss_cc: 0.0058, Acc_cc: 0.9972\n",
      "Epoch : 59 - val_loss: 5.3011, val_acc: 0.8252 - ba: 0.5029\n",
      "\n",
      "Epoch : 59 - test_acc: 0.9039 - ba_test: 0.4889\n",
      "\n",
      "Epoch [60/10000], Step [186/359] Loss: 0.0000003576\n",
      "Epoch [60/10000], Loss_cc: 0.0010, Acc_cc: 0.9993\n",
      "Epoch : 60 - val_loss: 5.0592, val_acc: 0.7990 - ba: 0.5186\n",
      "\n",
      "Epoch : 60 - test_acc: 0.8127 - ba_test: 0.5315\n",
      "\n",
      "Epoch [61/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [61/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 61 - val_loss: 5.0992, val_acc: 0.8039 - ba: 0.5216\n",
      "\n",
      "Epoch : 61 - test_acc: 0.8304 - ba_test: 0.5043\n",
      "\n",
      "Epoch [62/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [62/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 62 - val_loss: 5.1132, val_acc: 0.7990 - ba: 0.5186\n",
      "\n",
      "Epoch : 62 - test_acc: 0.8333 - ba_test: 0.5059\n",
      "\n",
      "Epoch [63/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [63/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 63 - val_loss: 5.2982, val_acc: 0.8072 - ba: 0.5196\n",
      "\n",
      "Epoch : 63 - test_acc: 0.8686 - ba_test: 0.5066\n",
      "\n",
      "Epoch [64/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [64/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 64 - val_loss: 5.2478, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 64 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [65/10000], Step [186/359] Loss: 0.0000003179\n",
      "Epoch [65/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 65 - val_loss: 5.2047, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 65 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [66/10000], Step [186/359] Loss: 0.0000006258\n",
      "Epoch [66/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 66 - val_loss: 5.1676, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 66 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [67/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [67/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 67 - val_loss: 5.1355, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 67 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [68/10000], Step [186/359] Loss: 0.0000000795\n",
      "Epoch [68/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 68 - val_loss: 5.1006, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 68 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [69/10000], Step [186/359] Loss: 0.0000084042\n",
      "Epoch [69/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 69 - val_loss: 5.0720, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 69 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [70/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [70/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 70 - val_loss: 5.0364, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 70 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [71/10000], Step [186/359] Loss: 0.0000001192\n",
      "Epoch [71/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 71 - val_loss: 5.0057, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 71 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [72/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [72/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 72 - val_loss: 4.9760, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 72 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [73/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [73/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 73 - val_loss: 4.9483, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 73 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [74/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [74/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 74 - val_loss: 4.9247, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 74 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [75/10000], Step [186/359] Loss: 0.0000000894\n",
      "Epoch [75/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 75 - val_loss: 4.9002, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 75 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [76/10000], Step [186/359] Loss: 0.0000000298\n",
      "Epoch [76/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 76 - val_loss: 4.8720, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 76 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [77/10000], Step [186/359] Loss: 0.0000000099\n",
      "Epoch [77/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 77 - val_loss: 4.8516, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 77 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [78/10000], Step [186/359] Loss: 0.0000009835\n",
      "Epoch [78/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 78 - val_loss: 4.8274, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 78 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [79/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [79/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 79 - val_loss: 4.8007, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 79 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [80/10000], Step [186/359] Loss: 0.0000000596\n",
      "Epoch [80/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 80 - val_loss: 4.7789, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 80 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [81/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [81/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 81 - val_loss: 4.7632, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 81 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [82/10000], Step [186/359] Loss: 0.0000007749\n",
      "Epoch [82/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 82 - val_loss: 4.7465, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 82 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [83/10000], Step [186/359] Loss: 0.0000000894\n",
      "Epoch [83/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 83 - val_loss: 4.7236, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 83 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [84/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [84/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 84 - val_loss: 4.7097, val_acc: 0.8072 - ba: 0.5235\n",
      "\n",
      "Epoch : 84 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [85/10000], Step [186/359] Loss: 0.0000001788\n",
      "Epoch [85/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 85 - val_loss: 4.6939, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 85 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [86/10000], Step [186/359] Loss: 0.0000008345\n",
      "Epoch [86/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 86 - val_loss: 4.6809, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 86 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [87/10000], Step [186/359] Loss: 0.0000097750\n",
      "Epoch [87/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 87 - val_loss: 4.6649, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 87 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [88/10000], Step [186/359] Loss: 0.0000000000\n",
      "Epoch [88/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 88 - val_loss: 4.6489, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 88 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [89/10000], Step [186/359] Loss: 0.0000039835\n",
      "Epoch [89/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n",
      "Epoch : 89 - val_loss: 4.6346, val_acc: 0.8088 - ba: 0.5245\n",
      "\n",
      "Epoch : 89 - test_acc: 0.8716 - ba_test: 0.5266\n",
      "\n",
      "Epoch [90/10000], Step [186/359] Loss: 0.0000002086\n",
      "Epoch [90/10000], Loss_cc: 0.0000, Acc_cc: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m     epoch_val_accuracy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(valid_loader)\n\u001b[1;32m    106\u001b[0m     epoch_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(valid_loader)\n\u001b[0;32m--> 108\u001b[0m     pred\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m    109\u001b[0m     real\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()))\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m#df_pred = pd.DataFrame(pred)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m#df_pred.to_csv(\"output_downstream/pred_real/pred_.csv\")\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m#df_real = pd.DataFrame(real)\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m#df_real.to_csv(\"output_downstream/real.csv\")\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "# 定义丢失函数和优化器\n",
    "#w = torch.Tensor([0.22, 0.365, 0.415])  \n",
    "w = torch.Tensor([0.1,0.9]) \n",
    "# 设定阴性和阳性的惩罚比例，这里是胡乱取的数\n",
    "criterion = nn.CrossEntropyLoss(w).to(device)\n",
    "optimizer = torch.optim.AdamW(vit.parameters(), lr=3e-4, weight_decay = 0.05, eps = 1e-4, betas = [0.9, 0.95])\n",
    "#scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "# 原始文献lr=1e-4，\n",
    "# lucidrains为3e-5，且使用了scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "# 生成输出文件\n",
    "fconv = open(os.path.join(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/convergence.csv\"), \"w\")\n",
    "fconv.write(\"epoch, metric, value\\n\")\n",
    "fconv.close()\n",
    "\n",
    "# 正式训练和验证\n",
    "# 此处杀bug的重要心得：若出现TypeError: cannot convert the series to <class 'float'>，\n",
    "# 表示生成的pathids_train_1024.db，或pathids_test_1024.db里有空缺的标签值，可通过\n",
    "# 同名的xlsx进行查看。此处发现“202017947.A3.bif”切片未生成标签值，遂直接删除.\n",
    "#best_or = 1\n",
    "best_ba = 0\n",
    "#global best_or\n",
    "global best_ba\n",
    "\n",
    "#total_step_0 = len(train_loader_0)\n",
    "total_step_1 =  len(train_loader)\n",
    "# 开始训练和验证\n",
    "for epoch in range(epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    epoch_accuracy_lung = 0\n",
    "    epoch_loss_lung = 0\n",
    "    epoch_accuracy = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    #for i, (images, labels) in enumerate(train_loader_0):\n",
    "        #torch.cuda.empty_cache()\n",
    "    #    images = images.to(device)\n",
    "    #    labels = labels.to(device)\n",
    "    #    outputs, _ = vit(images)\n",
    "    #    loss_lung = criterion(outputs, labels.long())\n",
    "        \n",
    "    #    optimizer.zero_grad()\n",
    "    #    loss_lung.backward()\n",
    "    #    optimizer.step()\n",
    "        \n",
    "    #    acc_lung = (outputs.argmax(dim=-1) == labels).float().mean()\n",
    "    #    epoch_accuracy_lung += acc_lung / len(train_loader_0)\n",
    "    #    epoch_loss_lung += loss_lung / len(train_loader_0)\n",
    "        \n",
    "    #    if (i + 1) % 2558 == 0:\n",
    "        #if (i + 1) % 5230 == 0:\n",
    "    #        print(\"Epoch [{}/{}], Step [{}/{}] Loss_lung: {:.10f}\"\n",
    "    #             .format(epoch+1, epochs, i+1, total_step_0, loss_lung))\n",
    "            \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #torch.cuda.empty_cache()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs, _ = vit(images)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (outputs.argmax(dim=-1) == labels).float().mean()\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "        \n",
    "        if (i + 1) % 186 == 0:\n",
    "        #if (i + 1) % 5230 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}] Loss: {:.10f}\"\n",
    "                 .format(epoch+1, epochs, i+1, total_step_1, loss))\n",
    "    \n",
    "    print(\"Epoch [{}/{}], Loss_cc: {:.4f}, Acc_cc: {:.4f}\".format(epoch+1, epochs, epoch_loss, epoch_accuracy))\n",
    "    \n",
    "    fconv = open(os.path.join(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/convergence.csv\"), \"a\")\n",
    "    #fconv.write(\"{}, loss_lung, {:.4f}\\n\".format(epoch+1, epoch_loss_lung))\n",
    "    #fconv.write(\"{}, acc_lung, {:.4f}\\n\".format(epoch+1, epoch_accuracy_lung))\n",
    "    fconv.write(\"{}, loss, {:.4f}\\n\".format(epoch+1, epoch_loss))\n",
    "    fconv.write(\"{}, acc, {:.4f}\\n\".format(epoch+1, epoch_accuracy))\n",
    "    fconv.close()\n",
    "        \n",
    "    if (epoch+1) % test_every == 0:\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            \n",
    "            pred = []\n",
    "            real = []\n",
    "            \n",
    "            for images, labels in valid_loader:\n",
    "                #torch.cuda.empty_cache()\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs, _ = vit(images)\n",
    "                val_loss = criterion(outputs, labels.long())\n",
    "                \n",
    "                #outputs = outputs.softmax(dim = -1)\n",
    "                outputs = outputs.argmax(dim = -1)\n",
    "                \n",
    "                acc = (outputs == labels).float().mean()\n",
    "                epoch_val_accuracy += acc / len(valid_loader)\n",
    "                epoch_val_loss += val_loss / len(valid_loader)\n",
    "            \n",
    "                pred.extend(list(outputs.cpu().numpy()))\n",
    "                real.extend(list(labels.cpu().numpy()))\n",
    "                \n",
    "            #df_pred = pd.DataFrame(pred)\n",
    "            #df_pred.to_csv(\"output_downstream/pred_real/pred_.csv\")\n",
    "            \n",
    "            #df_real = pd.DataFrame(real)\n",
    "            #df_real.to_csv(\"output_downstream/real.csv\")\n",
    "            \n",
    "            pred = np.array(pred)\n",
    "            real = np.array(real)\n",
    "            ba = balanced_accuracy_score(real, pred)\n",
    "            \n",
    "            # del pred real\n",
    "            # gc.collect()\n",
    "            \n",
    "            c={\"prediction\": pred, \"labels\": real}\n",
    "            df_c = pd.DataFrame(c)\n",
    "            df_c.to_csv(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/pred_real_inval/pred_{}.csv\".format(epoch+1))\n",
    "            \n",
    "            \n",
    "            #neq = np.not_equal(pred, real)\n",
    "            #acc = 1 - float(neq.sum()) / pred.shape[0]\n",
    "            \n",
    "            eq = np.equal(pred, real)\n",
    "            sensi = float(np.logical_and(pred==1, eq).sum()) / (real==1).sum()\n",
    "            speci = float(np.logical_and(pred==0, eq).sum()) / (real==0).sum()\n",
    "            \n",
    "            #fpr = float(np.logical_and(pred==1, neq).sum()) / (real==0).sum()\n",
    "            #fnr = float(np.logical_and(pred==0, neq).sum()) / (real==1).sum()\n",
    "            \n",
    "            #odds_ratio = (float(np.logical_and(pred==1, eq).sum()) * float(np.logical_and(pred==0, eq).sum())) \\\n",
    "            #            / (float(np.logical_and(pred==0, neq).sum()) * float(np.logical_and(pred==1, neq).sum()) + 1e-9)\n",
    "            \n",
    "            fconv = open(os.path.join(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/convergence.csv\"), \"a\")\n",
    "            fconv.write(\"{}, epoch_val_loss, {:.4f}\\n\".format(epoch+1, epoch_val_loss))\n",
    "            fconv.write(\"{}, val_acc, {:.4f}\\n\".format(epoch+1, epoch_val_accuracy))\n",
    "            fconv.write(\"{}, ba, {:.4f}\\n\".format(epoch+1, ba))\n",
    "            fconv.write(\"{}, sensi, {:.4f}\\n\".format(epoch+1, sensi))\n",
    "            fconv.write(\"{}, speci, {:.4f}\\n\".format(epoch+1, speci))\n",
    "            #fconv.write(\"{}, odds_ratio, {:.4f}\\n\".format(epoch+1, odds_ratio))\n",
    "            #fconv.write(\"{}, fpr, {}\\n\".format(epoch+1, fpr))\n",
    "            #fconv.write(\"{}, fnr, {}\\n\".format(epoch+1, fnr))\n",
    "            fconv.close()\n",
    "\n",
    "\n",
    "            epoch_test_accuracy = 0\n",
    "            #epoch_test_loss = 0\n",
    "            \n",
    "            pred_test = []\n",
    "            real_test = []\n",
    "            \n",
    "            for images, labels in valid_loader_1:\n",
    "                #torch.cuda.empty_cache()\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs, _ = vit(images)\n",
    "                #test_loss = criterion(outputs, labels.long())\n",
    "                \n",
    "                #outputs = outputs.softmax(dim = -1)\n",
    "                outputs = outputs.argmax(dim = -1)\n",
    "                \n",
    "                test_acc = (outputs == labels).float().mean()\n",
    "                epoch_test_accuracy += test_acc / len(valid_loader_1)\n",
    "                #epoch_test_loss += val_loss / len(valid_loader_1)\n",
    "            \n",
    "                pred_test.extend(list(outputs.cpu().numpy()))\n",
    "                real_test.extend(list(labels.cpu().numpy()))\n",
    "                \n",
    "            #df_pred = pd.DataFrame(pred)\n",
    "            #df_pred.to_csv(\"output_downstream/pred_real/pred_.csv\")\n",
    "            \n",
    "            #df_real = pd.DataFrame(real)\n",
    "            #df_real.to_csv(\"output_downstream/real.csv\")\n",
    "            \n",
    "            pred_test = np.array(pred_test)\n",
    "            real_test = np.array(real_test)\n",
    "            ba_test = balanced_accuracy_score(real_test, pred_test)\n",
    "            \n",
    "            # del pred real\n",
    "            # gc.collect()\n",
    "            \n",
    "            c6={\"prediction\": pred_test, \"labels\": real_test}\n",
    "            df_c6 = pd.DataFrame(c6)\n",
    "            df_c6.to_csv(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/pred_real_exval/pred_{}.csv\".format(epoch+1))\n",
    "            \n",
    "            #neq = np.not_equal(pred, real)\n",
    "            #acc = 1 - float(neq.sum()) / pred.shape[0]\n",
    "            \n",
    "            eq_test = np.equal(pred_test, real_test)\n",
    "            sensi_test = float(np.logical_and(pred_test==1, eq_test).sum()) / (real_test==1).sum()\n",
    "            speci_test = float(np.logical_and(pred_test==0, eq_test).sum()) / (real_test==0).sum()\n",
    "            \n",
    "            #fpr = float(np.logical_and(pred==1, neq).sum()) / (real==0).sum()\n",
    "            #fnr = float(np.logical_and(pred==0, neq).sum()) / (real==1).sum()\n",
    "            \n",
    "            #odds_ratio = (float(np.logical_and(pred==1, eq).sum()) * float(np.logical_and(pred==0, eq).sum())) \\\n",
    "            #            / (float(np.logical_and(pred==0, neq).sum()) * float(np.logical_and(pred==1, neq).sum()) + 1e-9)\n",
    "            \n",
    "            fconv = open(os.path.join(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/convergence.csv\"), \"a\")\n",
    "            #fconv.write(\"{}, epoch_val_loss, {:.4f}\\n\".format(epoch+1, epoch_val_loss))\n",
    "            fconv.write(\"{}, test_acc, {:.4f}\\n\".format(epoch+1, epoch_test_accuracy))\n",
    "            fconv.write(\"{}, ba_test, {:.4f}\\n\".format(epoch+1, ba_test))\n",
    "            fconv.write(\"{}, sensi_test, {:.4f}\\n\".format(epoch+1, sensi_test))\n",
    "            fconv.write(\"{}, speci_test, {:.4f}\\n\".format(epoch+1, speci_test))\n",
    "            #fconv.write(\"{}, odds_ratio, {:.4f}\\n\".format(epoch+1, odds_ratio))\n",
    "            #fconv.write(\"{}, fpr, {}\\n\".format(epoch+1, fpr))\n",
    "            #fconv.write(\"{}, fnr, {}\\n\".format(epoch+1, fnr))\n",
    "            fconv.close()\n",
    "            \n",
    "    #torch.save(vit.state_dict(), os.path.join(\"/data2/patho-vit_5_23_oc/low/4/7.17.2/checkpoint_3classes_{}.pth\".format(epoch+1)))\n",
    "        \n",
    "    #if ba >= best_ba:\n",
    "        # 或用 if ba >= best_ba:\n",
    "        #    best_or = odds_ratio\n",
    "    #    best_ba = ba\n",
    "        \n",
    "    torch.save(vit.state_dict(), os.path.join(\"/data2/patho-vit_5_23_ccsurv/patient/low/8/checkpoint_2classes_{}.pth\".format(epoch+1)))\n",
    "\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - val_loss: {epoch_val_loss:.4f}, val_acc: {epoch_val_accuracy:.4f} - ba: {ba:.4f}\\n\" \n",
    "    )\n",
    "    print(\n",
    "        f\"Epoch : {epoch+1} - test_acc: {epoch_test_accuracy:.4f} - ba_test: {ba_test:.4f}\\n\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb3888-8d3e-4add-ac4c-c677aea2e8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741b5fb-d612-4b91-8ac8-2cd6898dc25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eed331-037a-4fa2-a74a-173b02465016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401324fe-fc49-4893-9209-f0545231a533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57abfb2-0895-43ff-b825-db28ecd72118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c1101-9369-4f68-976c-e5e896b80849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3033048b-9c56-4348-8b8b-245c902b7d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ea22d-22bf-43c1-9b3c-86677f260c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266d3c7-68d4-4dd2-8681-b33e3c19421c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f508ed-97cf-41ae-96db-fc257fc3ab1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dcdb1-56d4-4eeb-bf44-b54dfe4b4a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44265a5e-d4af-469c-9942-52cc83f6174a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c18f80-8968-4163-8867-f457bbce6bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6fc10-5996-46a6-bfd2-ec6cef9d446c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2023",
   "language": "python",
   "name": "2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
